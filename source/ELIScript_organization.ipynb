{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#ORGANIZING-DATA\" data-toc-modified-id=\"ORGANIZING-DATA-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>ORGANIZING DATA</a></span><ul class=\"toc-item\"><li><span><a href=\"#Importing-libraries-and-modules\" data-toc-modified-id=\"Importing-libraries-and-modules-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>Importing libraries and modules</a></span></li><li><span><a href=\"#Defining-working-directory\" data-toc-modified-id=\"Defining-working-directory-1.2\"><span class=\"toc-item-num\">1.2&nbsp;&nbsp;</span>Defining working directory</a></span></li><li><span><a href=\"#Function-to-concatenate-files\" data-toc-modified-id=\"Function-to-concatenate-files-1.3\"><span class=\"toc-item-num\">1.3&nbsp;&nbsp;</span>Function to concatenate files</a></span></li><li><span><a href=\"#Applying-function\" data-toc-modified-id=\"Applying-function-1.4\"><span class=\"toc-item-num\">1.4&nbsp;&nbsp;</span>Applying function</a></span></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ORGANIZING DATA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing libraries and modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing libraries\n",
    "import os\n",
    "from os import chdir\n",
    "from glob import glob\n",
    "import pandas as pd\n",
    "import csv\n",
    "\n",
    "# config max columns and rows to show\n",
    "pd.set_option('display.max_columns', 2000)\n",
    "pd.set_option('display.max_rows', 50000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining working directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/home/sarah/Codes/eliscript/db/AFRICA/',\n",
       " '/home/sarah/Codes/eliscript/db/ANTARCTICA/',\n",
       " '/home/sarah/Codes/eliscript/db/ASIA/',\n",
       " '/home/sarah/Codes/eliscript/db/EUROPE/',\n",
       " '/home/sarah/Codes/eliscript/db/NCA/',\n",
       " '/home/sarah/Codes/eliscript/db/OCEANIA/',\n",
       " '/home/sarah/Codes/eliscript/db/SouthAmerica/',\n",
       " '/home/sarah/Codes/eliscript/db/africa.csv/',\n",
       " '/home/sarah/Codes/eliscript/db/antarctica.csv/',\n",
       " '/home/sarah/Codes/eliscript/db/asia.csv/',\n",
       " '/home/sarah/Codes/eliscript/db/europe.csv/',\n",
       " '/home/sarah/Codes/eliscript/db/northamerica.csv/',\n",
       " '/home/sarah/Codes/eliscript/db/oceania.csv/',\n",
       " '/home/sarah/Codes/eliscript/db/southamerica.csv/',\n",
       " '/home/sarah/Codes/eliscript/db/worldwide.csv/']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p1 = os.getcwd() \n",
    "path = os.path.dirname(p1)\n",
    "wdir = os.path.join(path, \"db\", \"\")\n",
    "\n",
    "folders = sorted(os.listdir(wdir))\n",
    "\n",
    "list_of_folders = []\n",
    "\n",
    "for folder in folders:\n",
    "    string = os.path.join(wdir + folder + \"/\")\n",
    "    list_of_folders.append(string)\n",
    "    \n",
    "list_of_folders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function to concatenate files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def concatenate_files(list_of_files, path, name):\n",
    "    \n",
    "    fieldnames = []\n",
    "    \n",
    "    for filename in list_of_files:\n",
    "        with open(filename, \"r\", newline=\"\") as f_in:\n",
    "            reader = csv.reader(f_in)\n",
    "            headers = next(reader)\n",
    "\n",
    "            for h in headers:\n",
    "                try:\n",
    "                    if h not in fieldnames:\n",
    "                        fieldnames.append(h)\n",
    "                        \n",
    "                except StopIteration:\n",
    "                    print('Done!')\n",
    "                \n",
    "    # Then copy the data\n",
    "    \n",
    "        \n",
    "    with open(path + \"{}.csv\".format(name), \"w\", newline=\"\") as f_out:   \n",
    "        writer = csv.DictWriter(f_out, fieldnames = fieldnames)\n",
    "        writer.writeheader()\n",
    "\n",
    "        for filename in list_of_files:\n",
    "            with open(filename, \"r\", newline=\"\") as f_in:\n",
    "                reader = csv.DictReader(f_in)  # Uses the field names in this file\n",
    "                for line in reader:\n",
    "                    writer.writerow(line)\n",
    "\n",
    "    return fieldnames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Applying function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['eprintid',\n",
       " 'rev_number',\n",
       " 'eprint_status',\n",
       " 'userid',\n",
       " 'importid',\n",
       " 'source',\n",
       " 'dir',\n",
       " 'datestamp',\n",
       " 'lastmod',\n",
       " 'status_changed',\n",
       " 'type',\n",
       " 'succeeds',\n",
       " 'commentary',\n",
       " 'metadata_visibility',\n",
       " 'contact_email',\n",
       " 'latitude',\n",
       " 'longitude',\n",
       " 'relation_type',\n",
       " 'relation_uri',\n",
       " 'item_issues_id',\n",
       " 'item_issues_type',\n",
       " 'item_issues_description',\n",
       " 'item_issues_timestamp',\n",
       " 'item_issues_status',\n",
       " 'item_issues_reported_by',\n",
       " 'item_issues_resolved_by',\n",
       " 'item_issues_comment',\n",
       " 'item_issues_count',\n",
       " 'sword_depositor',\n",
       " 'sword_slug',\n",
       " 'creators_name.family',\n",
       " 'creators_name.given',\n",
       " 'creators_name.lineage',\n",
       " 'creators_name.honourific',\n",
       " 'creators_id',\n",
       " 'contributors_type',\n",
       " 'contributors_name.family',\n",
       " 'contributors_name.given',\n",
       " 'contributors_name.lineage',\n",
       " 'contributors_name.honourific',\n",
       " 'contributors_id',\n",
       " 'corp_creators',\n",
       " 'title',\n",
       " 'ispublished',\n",
       " 'subjects',\n",
       " 'divisions',\n",
       " 'full_text_status',\n",
       " 'monograph_type',\n",
       " 'pres_type',\n",
       " 'keywords',\n",
       " 'note',\n",
       " 'abstract',\n",
       " 'date',\n",
       " 'date_type',\n",
       " 'series',\n",
       " 'publication',\n",
       " 'volume',\n",
       " 'number',\n",
       " 'publisher',\n",
       " 'place_of_pub',\n",
       " 'pagerange',\n",
       " 'pages',\n",
       " 'event_title',\n",
       " 'event_location',\n",
       " 'event_dates',\n",
       " 'event_type',\n",
       " 'id_number',\n",
       " 'patent_applicant',\n",
       " 'institution',\n",
       " 'department',\n",
       " 'thesis_type',\n",
       " 'refereed',\n",
       " 'isbn',\n",
       " 'issn',\n",
       " 'book_title',\n",
       " 'editors_name.family',\n",
       " 'editors_name.given',\n",
       " 'editors_name.lineage',\n",
       " 'editors_name.honourific',\n",
       " 'editors_id',\n",
       " 'official_url',\n",
       " 'related_url_url',\n",
       " 'related_url_type',\n",
       " 'referencetext',\n",
       " 'funders',\n",
       " 'projects',\n",
       " 'output_media',\n",
       " 'exhibitors_name.family',\n",
       " 'exhibitors_name.given',\n",
       " 'exhibitors_name.lineage',\n",
       " 'exhibitors_name.honourific',\n",
       " 'exhibitors_id',\n",
       " 'num_pieces',\n",
       " 'composition_type',\n",
       " 'producers_name.family',\n",
       " 'producers_name.given',\n",
       " 'producers_name.lineage',\n",
       " 'producers_name.honourific',\n",
       " 'producers_id',\n",
       " 'conductors_name.family',\n",
       " 'conductors_name.given',\n",
       " 'conductors_name.lineage',\n",
       " 'conductors_name.honourific',\n",
       " 'conductors_id',\n",
       " 'lyricists_name.family',\n",
       " 'lyricists_name.given',\n",
       " 'lyricists_name.lineage',\n",
       " 'lyricists_name.honourific',\n",
       " 'lyricists_id',\n",
       " 'accompaniment',\n",
       " 'data_type',\n",
       " 'pedagogic_type',\n",
       " 'completion_time',\n",
       " 'task_purpose',\n",
       " 'skill_areas',\n",
       " 'copyright_holders',\n",
       " 'learning_level',\n",
       " 'gscholar_impact',\n",
       " 'gscholar_cluster',\n",
       " 'gscholar_datestamp',\n",
       " 'othersabs_othabstracts',\n",
       " 'othersabs_language',\n",
       " 'altloc',\n",
       " 'chapter',\n",
       " 'commref',\n",
       " 'linkdata',\n",
       " 'confdates',\n",
       " 'conference',\n",
       " 'confloc',\n",
       " 'linguabib',\n",
       " 'pubdom',\n",
       " 'reportno',\n",
       " 'countries',\n",
       " 'thesistype',\n",
       " 'handle',\n",
       " 'fp7_project',\n",
       " 'fp7_project_id',\n",
       " 'fp7_type',\n",
       " 'access_rights']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "name = [\"africa\", \"antarctica\", \"asia\", \"europe\", \"northamerica\", \"oceania\", \"southamerica\"]\n",
    "\n",
    "list_of_list = []\n",
    "\n",
    "for f, n in zip(list_of_folders, name):  \n",
    "    # locate csv files in specified directory\n",
    "    list_of_files = [file for file in sorted(glob(f + \"*.csv\"))]\n",
    "    # append list of csv files in \"list_of_list\"\n",
    "    list_of_list.append(list_of_files)\n",
    "    #concatenate files in list_of_files\n",
    "    concatenate_files(list_of_files, wdir, n)\n",
    "\n",
    "\n",
    "# turn lists inside list_of_list into a single list\n",
    "worldwide_list = [item for sublist in list_of_list for item in sublist]\n",
    "# concatenate files, generating a single csv file\n",
    "concatenate_files(worldwide_list, wdir, \"worldwide\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
